{"cells":[{"cell_type":"markdown","metadata":{"id":"tggEl6a8IjHx"},"source":["import packages\n","------------------\n","\n","Some packages are installed automatically if you use Anaconda. As pytorch is used here, you are expected to install that in your machine. "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"0Dzmo4dOJcTl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116558805,"user_tz":360,"elapsed":77102,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"c9b029ce-0141-4cb0-cf5a-f111e00cc69d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","# drive.flush_and_unmount()\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dyq8L-NBKPWv","executionInfo":{"status":"ok","timestamp":1675116559620,"user_tz":360,"elapsed":820,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["# added to be able to run in Google Colab\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/UTRECHT/utils')\n","sys.path.insert(0,'/content/gdrive/MyDrive/UTRECHT')\n","\n","import utils"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7m1Ta0akIjIA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116568036,"user_tz":360,"elapsed":8418,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"46d3508b-7203-41ee-e08e-8df6f3a4bede"},"outputs":[{"output_type":"stream","name":"stdout","text":["3.8.10 (default, Nov 14 2022, 12:59:47) \n","[GCC 9.4.0]\n","1.13.1+cu116\n"]}],"source":["from __future__ import print_function, division\n","import os, random, time, copy\n","from skimage import io, transform, morphology, feature, measure\n","from skimage.morphology import dilation, square, binary_opening\n","from skimage.draw import rectangle_perimeter, circle_perimeter, disk\n","import numpy as np\n","import os.path as path\n","import scipy.io as sio\n","import scipy\n","from scipy import misc\n","from scipy import ndimage, signal\n","from scipy.ndimage import gaussian_filter\n","import pickle\n","import sys\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import PIL.Image\n","from io import BytesIO\n","from skimage import data, img_as_float\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","import pandas as pd \n","import matplotlib.patheffects as path_effects\n","import json\n","\n","from skimage.filters import threshold_otsu\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler \n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision\n","from torchvision import datasets, models, transforms\n","\n","# sys.path.append('/home/skong2/project/dpff4ldl')\n","# from utils.metrics import *\n","# from losses import *\n","\n","from utils.flow_functions import *\n","from utils.dataset import *\n","from utils.network_arch import *\n","from utils.trainval_detSegDistTransform import *\n","\n","import warnings # ignore warnings\n","warnings.filterwarnings(\"ignore\")\n","print(sys.version)\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"E8xdQF1zIjIT"},"source":["\n","\n","Evaluation and Visualization\n","-----"]},{"cell_type":"code","source":["#### set project name, save directory for the project\n","\n","exp_dir = '/content/gdrive/MyDrive/exp/05_Exp3_ContinuousTraining' \n","\n","trial_list = ['Trial_01', 'Trial_02','Trial_03','Trial_04','Trial_05']\n","time_step_list =['T0','T1','T2','Full']\n","trial = trial_list[1]    # set to the trial number\n","time_step = time_step_list[2] # set to time step number\n","t_minus_1_time_step = time_step_list[1] # set to previous time step\n","\n","save_dir = os.path.join(exp_dir, trial, time_step) \n","\n","eval_dir = '/content/gdrive/MyDrive/eval/05_Exp3_ContinuousTraining' \n","eval_dir = os.path.join(eval_dir, trial, time_step) \n","if not os.path.exists(eval_dir): \n","    os.makedirs(eval_dir)\n","\n","print(time_step)\n","print(t_minus_1_time_step)\n","print(eval_dir)"],"metadata":{"id":"o-ZQrBiUQIHe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116568776,"user_tz":360,"elapsed":743,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"306623f4-eae9-4c66-ff76-a4ccbd92af53"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["T2\n","T1\n","/content/gdrive/MyDrive/eval/05_Exp3_ContinuousTraining/Trial_02/T2\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"0eeI_ZiCw5Um","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116569585,"user_tz":360,"elapsed":302,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"79a7f54f-8a60-4276-9809-ee60f59e72c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# cpu or cuda\n","device ='cpu'\n","if torch.cuda.is_available(): \n","    device='cuda:0'\n","print(device)\n","\n","freqShow = 50\n","weight_reg = 2.0    # balances regression loss with segmentation loss. Value chosen based on past investigation.\n","weight_background = 0.1   # for regression loss only, downweights background pixels to highlight foreground pollen\n","\n","#model parameters\n","batch_size = 4\n","newSize = [800,800] # set to crop size, to tell model what size tensor to expect\n","total_epoch_num = 100  # total number of epoch in training\n","base_lr =0.0005        #0.0005      # base learning rate/\n","scaleList = [0]      # the number of output layer for U-net\n","#scale = [0,1,2,3]      # the number of output layer for U-net"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Am-jrOoEw5Uo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116572187,"user_tz":360,"elapsed":2604,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"c9e0f85d-ab16-4086-dabb-5a5de85afb8c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(dict_keys(['train_det_list', 'test_det_list']), 240, 60)"]},"metadata":{},"execution_count":6}],"source":["# path_to_image = '/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999/C6/C6_tiles_withAnnot'\n","path_to_image = '/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999'\n","with open(os.path.join(save_dir,'dbinfo.pkl'), 'rb') as handle:\n","    dbinfo = pickle.load(handle)    \n","    \n","dbinfo.keys(), len(dbinfo['train_det_list']), len(dbinfo['test_det_list'])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"RrCeZZtJw5Up","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116592271,"user_tz":360,"elapsed":20087,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"e380e1f8-8051-44c3-9012-2466d9db2c41"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","/content/gdrive/MyDrive/exp/05_Exp3_ContinuousTraining/Trial_02/T1/bestValModel_encoder.paramOnly\n"]}],"source":["################## init model ###################\n","path_to_save_paramOnly = path.join(exp_dir, trial, t_minus_1_time_step, 'bestValModel_encoder.paramOnly')\n","\n","curmodel = PollenDet_SegDistTransform(34, scaleList=scaleList, pretrained=False)\n","curmodel.encoder.encoder.conv1 = nn.Conv2d(27, 64, (7, 7), (2, 2), (3, 3), bias=False) #change dimensions of the first layer in the encoder\n","curmodel.load_state_dict(torch.load(path_to_save_paramOnly)) #, map_location=torch.device('cpu')\n","curmodel.to(device);    \n","#print(curmodel.state_dict)\n","curmodel.eval()\n","#curmodel.train()\n","curmodel.training = False\n","print(curmodel.training)\n","print(path_to_save_paramOnly)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nOlT4gd_Vdcb","executionInfo":{"status":"ok","timestamp":1675116592271,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["class PollenDet4Eval(Dataset):\n","    def __init__(self, path_to_image='/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999',\n","                #  path_to_annot='/content/gdrive/MyDrive/UTRECHT/Detection/AnnotCombo9_noNPP_circleMask',\n","                 path_to_mask='/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999',\n","                 dbinfo=dbinfo,\n","                 size=[1040,1392], \n","                 set_name='test'):\n","        \n","        self.path_to_image = path_to_image\n","        # self.path_to_annot = path_to_annot\n","        self.path_to_mask = path_to_mask\n","        self.transform = transform\n","        self.dbinfo = dbinfo\n","        if set_name=='val':\n","            set_name = 'test'\n","        self.set_name = set_name        \n","        self.size = size\n","        self.resizeFactor = size[0]/1000\n","        \n","        self.sampleList = self.dbinfo[set_name+'_det_list']\n","\n","        self.TFNormalize = transforms.Normalize([0.5] * 27, [0.5]*27)\n","        self.current_set_len = len(self.sampleList)\n","        \n","        self.TF2tensor = transforms.ToTensor()\n","        self.TF2PIL = transforms.ToPILImage()\n","        self.TFresize = transforms.Resize((self.size[0],self.size[1]))\n","\n","    def __len__(self):        \n","        return self.current_set_len\n","    \n","    def __getitem__(self, idx):        \n","        current_example= self.sampleList[idx] \n","\n","        current_image_path= os.path.join(self.path_to_image, current_example[0], current_example[0] + '_tiles_withAnnot', current_example[1],current_example[2])\n","        current_distTransform_path=os.path.join(self.path_to_image, current_example[0], current_example[0] + '_masks2', current_example[1],current_example[2])\n","        # curPickleName = path.join(self.path_to_annot, current_example)\n","\n","        imagestack_array = []\n","        for file in sorted(os.listdir(current_image_path)):\n","          if file.endswith('.png'):\n","            slice = Image.open(os.path.join(current_image_path, file))\n","            imagestack_array.append(np.asarray(slice))\n","        image = np.block(imagestack_array)\n","        if image.shape[2] <27:\n","          pad_val = 27-image.shape[2]\n","          npad = ((0, 0), (0,0), (0,pad_val))\n","          image= np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n","\n","        for file in sorted(os.listdir(current_distTransform_path)):\n","          if file.endswith('.png'):\n","            mask = Image.open(os.path.join(current_distTransform_path, file))\n","            mask=np.expand_dims(mask, axis=2)           \n","\n","        label = np.copy(mask)         # 11/30/21 added\n","        label[label > 0] = 1          # 11/30/21 added       \n","\n","        image_label = np.concatenate((image, label, mask), axis=2) #12/13/21 added\n","\n","\n","        mask_distanceTransform = np.copy(mask)     #11/18/21 edited\n","        \n","        labelOrgSize = np.copy(mask)\n","        labelOrgSize = torch.from_numpy(labelOrgSize).unsqueeze(0).unsqueeze(0).squeeze(4)\n","\n","        mask_distanceTransform = mask_distanceTransform.astype(np.float32)/100.0/self.resizeFactor  # factor=size[0]/1000\n","\n","        image = self.TF2tensor(image)\n","        label = torch.from_numpy(label).unsqueeze(0) # self.TF2tensor(label)       \n","        mask_distanceTransform = torch.from_numpy(mask_distanceTransform).unsqueeze(0) # self.TF2tensor(mask_distanceTransform)\n","\n","        image = image.unsqueeze(0)\n","        label = label.unsqueeze(0)        \n","        mask_distanceTransform = mask_distanceTransform.unsqueeze(0)       \n","\n","        height,width,layer = image_label.shape\n","        crop0 = image_label[0:800, 0:800,:]\n","        crop1 = image_label[0:800, width-800:,:]\n","        crop2 = image_label[height-800:, 0:800,:]\n","        crop3 = image_label[height-800:, width-800:,:]\n","\n","        croplist = [crop0, crop1, crop2, crop3]\n","        imgList=[]\n","        labelList=[]\n","        mask_DTList=[]\n","\n","        for idx2 in range(len(croplist)):\n","          image_label = croplist[idx2]\n","          image_label = self.TF2tensor(image_label)\n","          image_label = image_label.unsqueeze(0)  \n","          image = torch.narrow(image_label, 1, 0, image_label.shape[1]-2) \n","          label=torch.narrow(image_label, 1, image_label.shape[1]-2, 1) \n","          mask_distanceTransform=torch.narrow(image_label, 1, image_label.shape[1]-1, 1)\n","\n","          image_label = image_label.squeeze(0)\n","          image = image.type(torch.float)\n","          image = self.TFNormalize(image)\n","\n","          imgList.append(image)\n","          labelList.append(label)\n","          mask_DTList.append(mask_distanceTransform)\n","\n","        image = torch.concat(imgList)\n","        label = torch.concat(labelList)\n","        mask_distanceTransform = torch.concat(mask_DTList)\n","\n","        image = image.squeeze(0)\n","        label = label.squeeze(0)\n","        mask_distanceTransform = mask_distanceTransform.squeeze(0)\n","        labelOrgSize = labelOrgSize.squeeze(0)\n","\n","        return image, label, mask_distanceTransform, labelOrgSize, current_example\n","        # return image, label, mask_distanceTransform, mask_overlap, mask_voteX, mask_voteY, mask_peaks, mask_radius, labelOrgSize, mask_peaksOrgSize, mask_distanceTransformOrgSize, mask_radiusOrgSize"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xlcosSpxSjC0","executionInfo":{"status":"ok","timestamp":1675116592272,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["# set_name = 'test'\n","set_name = 'train'\n","det_datasets = PollenDet4Eval(path_to_image=path_to_image,\n","                              # path_to_annot=path_to_annotCombo,\n","                              dbinfo=dbinfo, size=newSize, set_name=set_name)\n","\n","dataloaders = DataLoader(det_datasets,\n","                         batch_size=1,\n","                         shuffle=True, \n","                         num_workers=8) # num_work can be set to batch_size\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Ho1DmlE4yO6S","executionInfo":{"status":"ok","timestamp":1675116592272,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["def create_circular_mask(mask, center, radius, value=1):\n","    h, w = mask.shape[:2]\n","    Y, X = np.ogrid[:h, :w]\n","    dist_from_center = np.sqrt((Y - center[0])**2 + (X-center[1])**2)\n","\n","    tmpMask = dist_from_center <= radius\n","    mask[tmpMask] = value\n","    \n","    return mask"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"9PvqXiRYAaGC","executionInfo":{"status":"ok","timestamp":1675116592273,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["def IOU(box1, box2):\n","    \"\"\"\n","We assume that the box follows the format:\n","box1 = [x1,y1,x2,y2], and box2 = [x3,y3,x4,y4],\n","where (x1,y1) and (x3,y3) represent the top left coordinate,\n","and (x2,y2) and (x4,y4) represent the bottom right coordinate\n","    \"\"\"\n","    x1, y1, x2, y2 = box1\t\n","    x3, y3, x4, y4 = box2\n","    \n","    assert x1 < x2\n","    assert y1 < y2\n","    assert x3 < x4\n","    assert y3 < y4\n","\n","    # determine the coordinates of the intersection rectangle\n","    x_left = max(x1, x3)\n","    y_top = max(y1, y3)\n","    x_right = min(x2, x4)\n","    y_bottom = min(y2, y4)\n","\n","    if x_right < x_left or y_bottom < y_top:\n","        return 0.0\n","\n","    # The intersection of two axis-aligned bounding boxes is always an\n","    # axis-aligned bounding box\n","    intersection_area = (x_right - x_left + 1) * (y_bottom - y_top + 1)\n","    \n","    # compute the area of both AABBs\n","    bb1_area = (x2 - x1) * (y2 - y1)\n","    bb2_area = (x4 - x3) * (y4 - y3)\n","\n","    # compute the intersection over union by taking the intersection\n","    # area and dividing it by the sum of prediction + ground-truth\n","    # areas - the interesection area\n","    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n","    assert iou >= 0.0\n","    assert iou <= 1.0\n","    return iou"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8xBcZh1UlUo7","executionInfo":{"status":"ok","timestamp":1675116592273,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["def nms(boxes, conf_threshold=0.1, iou_threshold=0.5):\n","    bbox_list_thresholded = []\n","    bbox_list_new = []\n","    bbox_list_new_txt = []\n","    # detMask_info = detMask_info\n","\n","    # Stage 1: sort boxes, filter out boxes with low confidence\n","    boxes_sorted = sorted(boxes, reverse=True, key = lambda x : x[1])\n","    for box in boxes_sorted:\n","        if box[1] > conf_threshold:\n","            bbox_list_thresholded.append(box)\n","        else:\n","            pass\n","    # Stage 2: loop through the boxes, remove boxes with high IoU\n","    while len(bbox_list_thresholded) > 0:\n","        current_box = bbox_list_thresholded.pop(0)\n","        bbox_list_new.append(current_box)\n","        current_box_txt = (current_box[0], str(current_box[1]) , str(current_box[2]), str(current_box[3]), str(current_box[4]), str(current_box[5]) )\n","        current_box_txt = ' '.join(current_box_txt)\n","        bbox_list_new_txt.append(current_box_txt)\n","\n","        for box in bbox_list_thresholded:\n","            if current_box[0] == box[0]:\n","                iou = IOU(current_box[2:], box[2:])\n","                # print(iou)\n","                if iou > iou_threshold:\n","                    bbox_list_thresholded.remove(box)\n","                    # detMask_info.remove()\n","\n","    return  bbox_list_new, bbox_list_new_txt"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"V0sHB0-VaI_g","executionInfo":{"status":"ok","timestamp":1675116592273,"user_tz":360,"elapsed":9,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"EIl_ym-OaIwk","executionInfo":{"status":"ok","timestamp":1675116592274,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Q3cmfvnEtrOv"},"source":["# Create corrected prediction masks"]},{"cell_type":"code","source":["# project_name = '05_Exp3_ContinuousTraining'\n","# model = [t_minus_1_time_step + '_model',time_step + '_model']"],"metadata":{"id":"wfGz2VZs66IG","executionInfo":{"status":"ok","timestamp":1675116592274,"user_tz":360,"elapsed":10,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# pred_masks_corrected = os.path.join('/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999/',current_example[0][0], 'pred_masks_corrected', current_example[1][0])\n","pred_mask_dir = os.path.join(save_dir, 'pred_masks') \n","\n","if not os.path.exists(pred_mask_dir): \n","    os.makedirs(pred_mask_dir)\n","print(pred_mask_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55cKyGEaqVSk","executionInfo":{"status":"ok","timestamp":1675117506033,"user_tz":360,"elapsed":313,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"771d8739-1c30-4d0e-b2e4-37b21ad8dc4c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/exp/05_Exp3_ContinuousTraining/Trial_02/T2/pred_masks\n"]}]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWBfFDtq7i5g","executionInfo":{"status":"ok","timestamp":1675117865598,"user_tz":360,"elapsed":349974,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"9612e6f7-b6bb-4d19-fa8a-4c8db0505636"},"outputs":[{"output_type":"stream","name":"stdout","text":["50/240\n","100/240\n","150/240\n","200/240\n"]}],"source":["iterCount, sampleCount = 0, 0\n","phase = 'train' # 'train'\n","for sample in dataloaders: \n","            \n","    curImg, curLabel, curMask, curMask_orgSize, current_example = sample\n","    \n","    curImg, curLabel, curMask, curMask_orgSize = curImg.to(device), curLabel.to(device), curMask.to(device), curMask_orgSize.to(device)\n","\n","    curImg_squeeze=torch.squeeze(curImg,0)\n","\n","    iterCount += 1\n","    sampleCount += curLabel.size(0)   \n","    \n","    outputs = curmodel(curImg_squeeze)\n","    predSeg = outputs[('segMask', 0)]\n","    predDistTransform = outputs[('output', 0)]\n","\n","    softmax = predSeg\n","    \n","    if iterCount%50==0:\n","        print('{}/{}'.format(iterCount,len(det_datasets)))\n","\n","    mask_dir =  os.path.join(pred_mask_dir, current_example[2][0])\n","    if os.path.exists(mask_dir):\n","      continue\n","    ##############################################\n","    ##          prediction: \n","    ##############################################\n","    # create a list of (800x800) prediction distance transforms crops and softmax crops\n","\n","    predDistTransform_crops=[]\n","    softmax_crops = []\n","\n","    for idx in range(0,4):\n","      tmpImg =  predDistTransform[idx,:,:,:].squeeze().cpu().detach().numpy() \n","      predDistTransform_crops.append(tmpImg)\n","\n","    for idx in range(0,4):\n","      tmpImg =  softmax[idx,:,:,:].squeeze().cpu().detach().numpy() \n","      softmax_crops.append(tmpImg)\n","\n","    # create full-sized pred distance transform \n","    mask_OrgSize = curMask_orgSize.squeeze().cpu().detach().numpy()\n","\n","    height,width = mask_OrgSize.shape\n","    predDistTransform=np.zeros_like(mask_OrgSize)  \n","    predDistTransform=predDistTransform.astype(np.float32)\n","\n","    tmp_predDistTransform_1=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_predDistTransform_2=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_predDistTransform_3=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_predDistTransform_4=np.zeros_like(mask_OrgSize).astype(np.float32)\n","\n","\n","    tmp_predDistTransform_1[0:800, 0:800]=predDistTransform_crops[0]\n","    tmp_predDistTransform_2[0:800, width-800:]=predDistTransform_crops[1]\n","    tmp_predDistTransform_3[height-800:, 0:800]=predDistTransform_crops[2]\n","    tmp_predDistTransform_4[height-800:, width-800:]=predDistTransform_crops[3]\n","\n","    predDistTransform = np.maximum.reduce([tmp_predDistTransform_1,tmp_predDistTransform_2,tmp_predDistTransform_3,tmp_predDistTransform_4]) \n","    predDistTransform = gaussian_filter(predDistTransform, sigma=10) # gaussian blur to get rid of shadow\n","    pred_distanceTransform = np.copy(predDistTransform)\n","\n","    # create full-sized softmax\n","    height,width = mask_OrgSize.shape\n","    softmax=np.zeros_like(mask_OrgSize)  \n","    softmax=softmax.astype(np.float32)\n","\n","    tmp_softmax_1=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_softmax_2=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_softmax_3=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_softmax_4=np.zeros_like(mask_OrgSize).astype(np.float32)\n","\n","    tmp_softmax_1[0:800, 0:800]=softmax_crops[0]\n","    tmp_softmax_2[0:800, width-800:]=softmax_crops[1]\n","    tmp_softmax_3[height-800:, 0:800]=softmax_crops[2]\n","    tmp_softmax_4[height-800:, width-800:]=softmax_crops[3]\n","\n","    tmp_softmax_1[tmp_softmax_1 == 0] = np.nan\n","    tmp_softmax_2[tmp_softmax_2 == 0] = np.nan\n","    tmp_softmax_3[tmp_softmax_3 == 0] = np.nan\n","    tmp_softmax_4[tmp_softmax_4 == 0] = np.nan\n","\n","    # softmax = np.maximum.reduce([tmp_softmax_1,tmp_softmax_2,tmp_softmax_3,tmp_softmax_4]) \n","    softmax =  np.nanmean(np.array([tmp_softmax_1,tmp_softmax_2,tmp_softmax_3,tmp_softmax_4]), axis=0)\n","\n","    # find peaks, zero-out background noise\n","    voting4center = np.copy(pred_distanceTransform)\n","    voting4center[voting4center<0.001] = 0\n","    coord_peaks = feature.peak_local_max(voting4center, min_distance=50, exclude_border=False) #originally min_distance =5, changed to 25\n","\n","    # list filenames for images in the stack\n","    slice_path=[]\n","    center_radius_list = []\n","    current_image_path= os.path.join(path_to_image, current_example[0][0], current_example[0][0] + '_tiles_withAnnot', current_example[1][0], current_example[2][0])\n","    for file in sorted(os.listdir(str(current_image_path))):\n","        if file.endswith('.png'):\n","          slice = os.path.join(str(current_image_path), file)\n","          slice_path.append(slice)\n","        if file.endswith('full_annot.plk'):\n","          with open(os.path.join(current_image_path,'full_annot.plk'), 'rb') as handle:\n","              tmpData = pickle.load(handle)\n","              # tmpData = json.load(f)            \n","              for shape in tmpData:\n","                  # full_annot.append(shape)\n","                  label_name = shape[\"label\"]\n","                  # if label_name in do_not_include:\n","                  #     continue\n","                  points = shape['points']\n","\n","                  # # export crop masks\n","                  xy = [tuple(point) for point in points]\n","                  (cx, cy), (px, py) = xy\n","                  d = math.sqrt((cx - px) ** 2 + (cy - py) ** 2)\n","                  center_radius_list.append((cx,cy,d,label_name))\n","                  \n","    # create detection mask using peaks and predicted radius\n","    centerMask = voting4center*0\n","    detMask = voting4center*0\n","    dist_transform_pred = voting4center*0\n","    predRadiusList = []\n","    detection_info = []\n","    detection_info2 = []\n","    # detMask_info = []\n","\n","    size = (400,400)\n","\n","    # i=0\n","\n","    for i in range(coord_peaks.shape[0]):\n","        y, x = coord_peaks[i]\n","        #centerMask[y, x] = 1\n","        centerMask[y-10:y+10, x-10:x+10] = 1\n","        # predRadiusList += [voting4center[y,x] *100*800/1000 * 800/1000] # /100.0/self.resizeFactor      # why smaller?\n","        # predRadiusList += [voting4center[y,x] *100*1000/1000 * 1000/1000]\n","\n","        left = int(x-(size[0]/2))\n","        left=max(left,0)\n","        top = int(y-(size[0]/2))\n","        top=max(top,0)\n","        right = int(x+(size[0]/2))\n","        right=max(right,0)\n","        bottom = int(y+(size[0]/2))\n","        bottom=max(bottom,0)\n","\n","        tmpCrop = softmax[top:bottom, left:right]\n","        if np.isnan(np.amax(tmpCrop)):\n","          continue\n","        thresh = threshold_otsu(tmpCrop) \n","        tmpCrop = tmpCrop> thresh # binarize\n","        tmpCrop= measure.label(tmpCrop, background=0)\n","        props = measure.regionprops(tmpCrop) #get the properties of the connected components\n","\n","        # diameter = [prop.feret_diameter_max for prop in props]\n","        # diameter = [prop.equivalent_diameter for prop in props]  #diameter for connected components\n","        diameter = [prop.major_axis_length for prop in props]   #diameter for connected components\n","        if len(diameter) !=0 and max(diameter)!=0:\n","          radius = int(max(diameter)/2)\n","          predRadiusList += [radius]\n","          a = len(predRadiusList)-1\n","\n","          tmpMask = voting4center*0\n","          tmpMask = create_circular_mask(tmpMask, [y, x], predRadiusList[a], value=1)\n","\n","          #write bb coords to file\n","          # bbox = [prop.bbox for prop in props]   #bounding box coordinates for connected components\n","\n","          class_name=\"det\"\n","          leftBb = x-radius\n","          leftBb = max(leftBb,0)\n","          topBb = y-radius\n","          topBb= max(topBb,0)\n","          rightBb = x+radius\n","          rightBb = max(rightBb, 0)\n","          bottomBb = y+radius\n","          bottomBb = max(bottomBb,0)\n","\n","          masked_softmax = np.ma.masked_where(tmpMask==0, softmax) \n","          confidence = np.nanmean(masked_softmax)\n","          if confidence > 0.99:\n","            confidence = 0\n","          # bbox_info = [class_name,str(confidence) , str(leftBb), str(topBb), str(rightBb), str(bottomBb)]\n","          bbox_info2 = [class_name, confidence, leftBb, topBb, rightBb, bottomBb]\n","          # circle_info = [y,x,radius]\n","\n","          # if confidence <0.05:\n","          #     continue\n","          # else:\n","          # detMask = create_circular_mask(detMask, [y, x], predRadiusList[a], value=a+1)\n","          # bbox_info = ' '.join(bbox_info)\n","          # detection_info.append(bbox_info)\n","          detection_info2.append(bbox_info2)\n","        # detMask_info.append(circle_info)\n","\n","        # Apply non-max suppression\n","        NMS_bb = nms(detection_info2,conf_threshold=0.01, iou_threshold=0.3)  # set to the proper confidence threshold\n","        NMS_bb = NMS_bb[0]\n","\n","        # print(predRadiusList)\n","        # print(detection_info)\n","        # print(detection_info2)\n","        # print(NMS_bb)\n","\n","        # plt.imshow(masked_softmax)\n","        # print(tmpMask)\n","\n","        ############################ attach class label ######################################################## \n","        pred_bb = [leftBb, topBb, rightBb, bottomBb]\n","        gt_bb_list = []\n","\n","        for j in range(len(center_radius_list)):\n","            cur_class_label_full = center_radius_list[j]\n","            code = str(cur_class_label_full[3])\n","            cy = int(center_radius_list[j][0])\n","            cx = int(center_radius_list[j][1])\n","            r = int(center_radius_list[j][2])\n","\n","            gt_leftBb = cy-r\n","            gt_topBb = cx-r\n","            gt_rightBb = cy+r\n","            gt_bottomBb = cx+r\n","            gt_bb = [gt_leftBb,gt_topBb,gt_rightBb,gt_bottomBb]\n","            gt_bb_list.append(gt_bb)\n","\n","            iou = IOU(gt_bb,pred_bb)\n","            a = len(gt_bb_list) - 1\n","            # print(iou)\n","            if iou>0.3:\n","                detMask = create_circular_mask(detMask, [cx, cy], r, value=a+1)\n","                dist_transform_pred = ndimage.distance_transform_edt(detMask)\n","                dist_transform_pred = dist_transform_pred.astype(np.uint8)\n","\n","\n","    # # fn = open(det_filename,'w')\n","    # fn = open(det_filename,'a')\n","    # for i in NMS_bb:\n","    #   fn.write(i + \"\\n\")\n","    # fn.close()\n","\n","\n","    ### export prediction masks\n","    mask_dir =  os.path.join(pred_mask_dir, current_example[2][0])\n","    if not os.path.exists(mask_dir): \n","        os.makedirs(mask_dir)\n","    mask_filename = os.path.join(mask_dir, 'pred_mask.png')\n","\n","    if isinstance(dist_transform_pred, np.ndarray):\n","        dist_transform_pred_tosave = PIL.Image.fromarray((dist_transform_pred).astype(np.uint8))\n","    dist_transform_pred_tosave.save(mask_filename)"]},{"cell_type":"code","source":["if len(NMS_bb) == 0:\n","  print('null')"],"metadata":{"id":"qmGb32LvOHuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675116912665,"user_tz":360,"elapsed":274,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"ea3fc619-2498-44f6-dfc5-c07f69b01d80"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["null\n"]}]},{"cell_type":"code","source":["        if len(NMS_bb) == 0:\n","            dist_transform_pred=np.zeros_like(mask_OrgSize)  \n","            ### export prediction masks\n","            mask_dir =  os.path.join(pred_mask_dir, current_example[2][0])\n","            if not os.path.exists(mask_dir): \n","                os.makedirs(mask_dir)\n","            mask_filename = os.path.join(mask_dir, 'pred_mask.png')\n","\n","            if isinstance(dist_transform_pred, np.ndarray):\n","                dist_transform_pred_tosave = PIL.Image.fromarray((dist_transform_pred).astype(np.uint8))\n","            dist_transform_pred_tosave.save(mask_filename)\n","\n","        else:"],"metadata":{"id":"9a66t9omvfW1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"11kX06MaXNoPtsXtPzqwFKOxKq-QkiU3J","timestamp":1643318796487},{"file_id":"19scDWQ4L79clhNFzHCUF6p4dOSg71kPZ","timestamp":1643243143306},{"file_id":"1LBR2EGgGSmP8F16tB17lU0udI9aGJOVE","timestamp":1642701132152},{"file_id":"1pbz8JGQbXgBsY0i68W2hbMnxv-HZrDzc","timestamp":1641538196383},{"file_id":"1Bf1dJz-tiEa39pj7_5xq6sIqy5sav7tG","timestamp":1641252892862},{"file_id":"1hWiEAazHjKMSjYgci-ZM-4RiRsl-xulx","timestamp":1639780045728},{"file_id":"1dFMFlSD7JumeBNAxDC1GO5I2vY_puom-","timestamp":1639751288360},{"file_id":"1_cGNWaPlb7RGYHbK0p5up6USl8Jqy5l_","timestamp":1638377383878},{"file_id":"1Jovw-ecDYWmrl2byWTMTtfH17w2p_rw1","timestamp":1636216349035},{"file_id":"13s6xpTJ8dA5aUQn1FjgYBwPhfJKO21cM","timestamp":1635990836913},{"file_id":"1wMpFpk61uyI6XoMQjnIvpuaCmVYCRmg6","timestamp":1633643078356}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}