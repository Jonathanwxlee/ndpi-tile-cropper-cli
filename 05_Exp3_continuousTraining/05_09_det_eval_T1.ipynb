{"cells":[{"cell_type":"markdown","metadata":{"id":"tggEl6a8IjHx"},"source":["import packages\n","------------------\n","\n","Some packages are installed automatically if you use Anaconda. As pytorch is used here, you are expected to install that in your machine. "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21150,"status":"ok","timestamp":1675717235493,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"},"user_tz":360},"id":"0Dzmo4dOJcTl","outputId":"9dafd807-5d56-46ed-a9f2-daa9826d5f90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","# drive.flush_and_unmount()\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dyq8L-NBKPWv","executionInfo":{"status":"ok","timestamp":1675717236282,"user_tz":360,"elapsed":792,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["# added to be able to run in Google Colab\n","import sys\n","sys.path.append('/content/gdrive/MyDrive/UTRECHT/utils')\n","sys.path.insert(0,'/content/gdrive/MyDrive/UTRECHT')\n","\n","import utils"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6723,"status":"ok","timestamp":1675717243002,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"},"user_tz":360},"id":"7m1Ta0akIjIA","outputId":"bd8dbbc7-59be-471f-a2ec-9b5481b21cba"},"outputs":[{"output_type":"stream","name":"stdout","text":["3.8.10 (default, Nov 14 2022, 12:59:47) \n","[GCC 9.4.0]\n","1.13.1+cu116\n"]}],"source":["from __future__ import print_function, division\n","import os, random, time, copy\n","from skimage import io, transform, morphology, feature, measure\n","from skimage.morphology import dilation, square, binary_opening\n","from skimage.draw import rectangle_perimeter\n","import numpy as np\n","import os.path as path\n","import scipy.io as sio\n","import scipy\n","from scipy import misc\n","from scipy import ndimage, signal\n","from scipy.ndimage import gaussian_filter\n","import pickle\n","import sys\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import PIL.Image\n","from io import BytesIO\n","from skimage import data, img_as_float\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","import pandas as pd \n","import matplotlib.patheffects as path_effects\n","\n","from skimage.filters import threshold_otsu\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler \n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torchvision\n","from torchvision import datasets, models, transforms\n","\n","# sys.path.append('/home/skong2/project/dpff4ldl')\n","# from utils.metrics import *\n","# from losses import *\n","\n","from utils.flow_functions import *\n","from utils.dataset import *\n","from utils.network_arch import *\n","from utils.trainval_detSegDistTransform import *\n","\n","import warnings # ignore warnings\n","warnings.filterwarnings(\"ignore\")\n","print(sys.version)\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{"id":"E8xdQF1zIjIT"},"source":["\n","\n","Evaluation and Visualization\n","-----"]},{"cell_type":"code","source":["#### set project name, save directory for the project\n","\n","exp_dir = '/content/gdrive/MyDrive/exp/05_Exp3_ContinuousTraining' \n","\n","trial_list = ['Trial_01', 'Trial_02','Trial_03','Trial_04','Trial_05']\n","time_step_list =['T0','T1','T2','Full']\n","trial = trial_list[3]    # set to the trial number\n","time_step = time_step_list[1] # set to time step number\n","t_minus_1_time_step = time_step_list[0] # set to previous time step\n","\n","save_dir = os.path.join(exp_dir, trial, time_step) \n","t_minus_1_save_dir = os.path.join(exp_dir, trial, t_minus_1_time_step)\n","\n","eval_dir = '/content/gdrive/MyDrive/eval/05_Exp3_ContinuousTraining' \n","eval_dir = os.path.join(eval_dir, trial, time_step) \n","if not os.path.exists(eval_dir): \n","    os.makedirs(eval_dir)\n","\n","print(time_step)\n","print(t_minus_1_time_step)\n","print(eval_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PAmvki6JFKZ","executionInfo":{"status":"ok","timestamp":1675717244042,"user_tz":360,"elapsed":1042,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"0d46483d-57f1-4d38-e5d3-c0d1827689e3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["T1\n","T0\n","/content/gdrive/MyDrive/eval/05_Exp3_ContinuousTraining/Trial_04/T1\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1675717244745,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"},"user_tz":360},"id":"0eeI_ZiCw5Um","outputId":"786a19f8-602a-429a-e3d7-60c291dc4818"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# Here define the path, which is used to save the log and trained model in training process\n","\n","# Tminus1_project_name = 'generalizedDet_2022_10_18'\n","\n","# cpu or cuda\n","device ='cpu'\n","if torch.cuda.is_available(): \n","    device='cuda:0'\n","print(device)\n","\n","freqShow = 50\n","weight_reg = 2.0    # balances regression loss with segmentation loss. Value chosen based on past investigation.\n","weight_background = 0.1   # for regression loss only, downweights background pixels to highlight foreground pollen\n","\n","#model parameters\n","batch_size = 4\n","newSize = [1040,1392]# set to crop size, to tell model what size tensor to expect\n","total_epoch_num = 60  # total number of epoch in training\n","base_lr =0.0005        #0.0005      # base learning rate/\n","scaleList = [0]      # the number of output layer for U-net\n","#scale = [0,1,2,3]      # the number of output layer for U-net"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":843,"status":"ok","timestamp":1675717254832,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"},"user_tz":360},"id":"Am-jrOoEw5Uo","outputId":"e003728e-8609-4950-d343-03b5075c4e4e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(dict_keys(['train_det_list', 'test_det_list']), 240, 60)"]},"metadata":{},"execution_count":7}],"source":["# path_to_image = '/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999/C6/C6_tiles_withAnnot'\n","path_to_image = '/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999'\n","with open(os.path.join(save_dir,'dbinfo.plk'), 'rb') as handle:\n","    dbinfo = pickle.load(handle)    \n","    \n","dbinfo.keys(), len(dbinfo['train_det_list']), len(dbinfo['test_det_list'])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21112,"status":"ok","timestamp":1675717280528,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"},"user_tz":360},"id":"RrCeZZtJw5Up","outputId":"371b78bc-d2cb-40be-a4bf-24eff34ab9fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","/content/gdrive/MyDrive/exp/05_Exp3_ContinuousTraining/Trial_04/T1/bestValModel_encoder.paramOnly\n"]}],"source":["################## init model ###################\n","path_to_save_paramOnly = path.join(save_dir, 'bestValModel_encoder.paramOnly')\n","\n","curmodel = PollenDet_SegDistTransform(34, scaleList=scaleList, pretrained=False)\n","curmodel.encoder.encoder.conv1 = nn.Conv2d(27, 64, (7, 7), (2, 2), (3, 3), bias=False) #change dimensions of the first layer in the encoder\n","curmodel.load_state_dict(torch.load(path_to_save_paramOnly)) #, map_location=torch.device('cpu')\n","curmodel.to(device);    \n","#print(curmodel.state_dict)\n","curmodel.eval()\n","#curmodel.train()\n","curmodel.training = False\n","print(curmodel.training)\n","print(path_to_save_paramOnly)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"nOlT4gd_Vdcb","executionInfo":{"status":"ok","timestamp":1675717280529,"user_tz":360,"elapsed":6,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["class PollenDet4Eval(Dataset):\n","    def __init__(self, path_to_image='/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999',\n","                #  path_to_annot='/content/gdrive/MyDrive/UTRECHT/Detection/AnnotCombo9_noNPP_circleMask',\n","                 path_to_mask='/content/gdrive/MyDrive/UTRECHT/Detection/PAL1999',\n","                 dbinfo=dbinfo,\n","                 size=[1040,1392], \n","                 set_name='test'):\n","        \n","        self.path_to_image = path_to_image\n","        # self.path_to_annot = path_to_annot\n","        self.path_to_mask = path_to_mask\n","        self.transform = transform\n","        self.dbinfo = dbinfo\n","        if set_name=='val':\n","            set_name = 'test'\n","        self.set_name = set_name        \n","        self.size = size\n","        self.resizeFactor = size[0]/1000\n","        \n","        self.sampleList = self.dbinfo[set_name+'_det_list']\n","\n","        self.TFNormalize = transforms.Normalize([0.5] * 27, [0.5]*27)\n","        self.current_set_len = len(self.sampleList)\n","        \n","        self.TF2tensor = transforms.ToTensor()\n","        self.TF2PIL = transforms.ToPILImage()\n","        self.TFresize = transforms.Resize((self.size[0],self.size[1]))\n","\n","    def __len__(self):        \n","        return self.current_set_len\n","    \n","    def __getitem__(self, idx):        \n","        current_example= self.sampleList[idx] \n","\n","        current_image_path= os.path.join(self.path_to_image, current_example[0], current_example[0] + '_tiles_withAnnot', current_example[1],current_example[2])\n","        current_distTransform_path=os.path.join(self.path_to_image, current_example[0], current_example[0] + '_masks2', current_example[1],current_example[2])\n","        # curPickleName = path.join(self.path_to_annot, current_example)\n","\n","        imagestack_array = []\n","        for file in sorted(os.listdir(current_image_path)):\n","          if file.endswith('.png'):\n","            slice = Image.open(os.path.join(current_image_path, file))\n","            imagestack_array.append(np.asarray(slice))\n","        image = np.block(imagestack_array)\n","        if image.shape[2] <27:\n","          pad_val = 27-image.shape[2]\n","          npad = ((0, 0), (0,0), (0,pad_val))\n","          image= np.pad(image, pad_width=npad, mode='constant', constant_values=0)\n","\n","        for file in sorted(os.listdir(current_distTransform_path)):\n","          if file.endswith('.png'):\n","            mask = Image.open(os.path.join(current_distTransform_path, file))\n","            mask=np.expand_dims(mask, axis=2)           \n","\n","        label = np.copy(mask)         # 11/30/21 added\n","        label[label > 0] = 1          # 11/30/21 added       \n","\n","        image_label = np.concatenate((image, label, mask), axis=2) #12/13/21 added\n","\n","\n","        mask_distanceTransform = np.copy(mask)     #11/18/21 edited\n","        \n","        labelOrgSize = np.copy(mask)\n","        labelOrgSize = torch.from_numpy(labelOrgSize).unsqueeze(0).unsqueeze(0).squeeze(4)\n","\n","        mask_distanceTransform = mask_distanceTransform.astype(np.float32)/100.0/self.resizeFactor  # factor=size[0]/1000\n","\n","        image = self.TF2tensor(image)\n","        label = torch.from_numpy(label).unsqueeze(0) # self.TF2tensor(label)       \n","        mask_distanceTransform = torch.from_numpy(mask_distanceTransform).unsqueeze(0) # self.TF2tensor(mask_distanceTransform)\n","\n","        image = image.unsqueeze(0)\n","        label = label.unsqueeze(0)        \n","        mask_distanceTransform = mask_distanceTransform.unsqueeze(0)       \n","\n","        height,width,layer = image_label.shape\n","        crop0 = image_label[0:800, 0:800,:]\n","        crop1 = image_label[0:800, width-800:,:]\n","        crop2 = image_label[height-800:, 0:800,:]\n","        crop3 = image_label[height-800:, width-800:,:]\n","\n","        croplist = [crop0, crop1, crop2, crop3]\n","        imgList=[]\n","        labelList=[]\n","        mask_DTList=[]\n","\n","        for idx2 in range(len(croplist)):\n","          image_label = croplist[idx2]\n","          image_label = self.TF2tensor(image_label)\n","          image_label = image_label.unsqueeze(0)  \n","          image = torch.narrow(image_label, 1, 0, image_label.shape[1]-2) \n","          label=torch.narrow(image_label, 1, image_label.shape[1]-2, 1) \n","          mask_distanceTransform=torch.narrow(image_label, 1, image_label.shape[1]-1, 1)\n","\n","          image_label = image_label.squeeze(0)\n","          image = image.type(torch.float)\n","          image = self.TFNormalize(image)\n","\n","          imgList.append(image)\n","          labelList.append(label)\n","          mask_DTList.append(mask_distanceTransform)\n","\n","        image = torch.concat(imgList)\n","        label = torch.concat(labelList)\n","        mask_distanceTransform = torch.concat(mask_DTList)\n","\n","        image = image.squeeze(0)\n","        label = label.squeeze(0)\n","        mask_distanceTransform = mask_distanceTransform.squeeze(0)\n","        labelOrgSize = labelOrgSize.squeeze(0)\n","\n","        return image, label, mask_distanceTransform, labelOrgSize, current_example\n","        # return image, label, mask_distanceTransform, mask_overlap, mask_voteX, mask_voteY, mask_peaks, mask_radius, labelOrgSize, mask_peaksOrgSize, mask_distanceTransformOrgSize, mask_radiusOrgSize"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"xlcosSpxSjC0","executionInfo":{"status":"ok","timestamp":1675717280529,"user_tz":360,"elapsed":6,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["set_name = 'test'\n","det_datasets = PollenDet4Eval(path_to_image=path_to_image,\n","                              # path_to_annot=path_to_annotCombo,\n","                              dbinfo=dbinfo, size=newSize, set_name=set_name)\n","\n","dataloaders = DataLoader(det_datasets,\n","                         batch_size=1,\n","                         shuffle=True, \n","                         num_workers=4) # num_work can be set to batch_size\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Ho1DmlE4yO6S","executionInfo":{"status":"ok","timestamp":1675717280529,"user_tz":360,"elapsed":5,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["def create_circular_mask(mask, center, radius, value=1):\n","    h, w = mask.shape[:2]\n","    Y, X = np.ogrid[:h, :w]\n","    dist_from_center = np.sqrt((Y - center[0])**2 + (X-center[1])**2)\n","\n","    tmpMask = dist_from_center <= radius\n","    mask[tmpMask] = value\n","    \n","    return mask"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9PvqXiRYAaGC","executionInfo":{"status":"ok","timestamp":1675717280530,"user_tz":360,"elapsed":6,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["def IOU(box1, box2):\n","    \"\"\"\n","We assume that the box follows the format:\n","box1 = [x1,y1,x2,y2], and box2 = [x3,y3,x4,y4],\n","where (x1,y1) and (x3,y3) represent the top left coordinate,\n","and (x2,y2) and (x4,y4) represent the bottom right coordinate\n","    \"\"\"\n","    x1, y1, x2, y2 = box1\t\n","    x3, y3, x4, y4 = box2\n","    \n","    assert x1 < x2\n","    assert y1 < y2\n","    assert x3 < x4\n","    assert y3 < y4\n","\n","    # determine the coordinates of the intersection rectangle\n","    x_left = max(x1, x3)\n","    y_top = max(y1, y3)\n","    x_right = min(x2, x4)\n","    y_bottom = min(y2, y4)\n","\n","    if x_right < x_left or y_bottom < y_top:\n","        return 0.0\n","\n","    # The intersection of two axis-aligned bounding boxes is always an\n","    # axis-aligned bounding box\n","    intersection_area = (x_right - x_left + 1) * (y_bottom - y_top + 1)\n","    \n","    # compute the area of both AABBs\n","    bb1_area = (x2 - x1) * (y2 - y1)\n","    bb2_area = (x4 - x3) * (y4 - y3)\n","\n","    # compute the intersection over union by taking the intersection\n","    # area and dividing it by the sum of prediction + ground-truth\n","    # areas - the interesection area\n","    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n","    assert iou >= 0.0\n","    assert iou <= 1.0\n","    return iou"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"8xBcZh1UlUo7","executionInfo":{"status":"ok","timestamp":1675717280530,"user_tz":360,"elapsed":6,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["def nms(boxes, conf_threshold=0.1, iou_threshold=0.5):\n","    bbox_list_thresholded = []\n","    bbox_list_new = []\n","    bbox_list_new_txt = []\n","    # detMask_info = detMask_info\n","\n","    # Stage 1: sort boxes, filter out boxes with low confidence\n","    boxes_sorted = sorted(boxes, reverse=True, key = lambda x : x[1])\n","    for box in boxes_sorted:\n","        if box[1] > conf_threshold:\n","            bbox_list_thresholded.append(box)\n","        else:\n","            pass\n","    # Stage 2: loop through the boxes, remove boxes with high IoU\n","    while len(bbox_list_thresholded) > 0:\n","        current_box = bbox_list_thresholded.pop(0)\n","        bbox_list_new.append(current_box)\n","        current_box_txt = (current_box[0], str(current_box[1]) , str(current_box[2]), str(current_box[3]), str(current_box[4]), str(current_box[5]) )\n","        current_box_txt = ' '.join(current_box_txt)\n","        bbox_list_new_txt.append(current_box_txt)\n","\n","        for box in bbox_list_thresholded:\n","            if current_box[0] == box[0]:\n","                iou = IOU(current_box[2:], box[2:])\n","                # print(iou)\n","                if iou > iou_threshold:\n","                    bbox_list_thresholded.remove(box)\n","                    # detMask_info.remove()\n","\n","    return  bbox_list_new, bbox_list_new_txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0sHB0-VaI_g"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIl_ym-OaIwk"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Visualization"],"metadata":{"id":"crw8QXlfn-Fb"}},{"cell_type":"code","source":["sampler = iter(dataloaders)"],"metadata":{"id":"qRQOeMyioCFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curImg, curLabel, curMask, curMask_orgSize, current_example = next(sampler)\n","# curImg, curBinaryMask, curDTMask, curImgPath = next(sampler)\n","print(current_example)\n","\n","curImg = curImg.to(device)\n","# curImg, curLabel, curMask, curMask_orgSize = curImg.to(device), curLabel.to(device), curMask.to(device), curMask_orgSize.to(device)\n","curImg_squeeze=torch.squeeze(curImg,0)\n","\n","outputs = curmodel(curImg_squeeze)\n","predSeg = outputs[('segMask', 0)]\n","predDistTransform = outputs[('output', 0)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3vItwTIoCQ6","executionInfo":{"status":"ok","timestamp":1675534605688,"user_tz":360,"elapsed":301,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"c141420a-8d40-4dcb-82dd-44da9e58af4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('C6',), ('PAL1999_C6_sample1_slide2',), ('42784x_59760y',)]\n"]}]},{"cell_type":"code","source":["print(predSeg.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofQEWWV9oGjT","executionInfo":{"status":"ok","timestamp":1675534606166,"user_tz":360,"elapsed":3,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"a1e8dcc4-29f3-4cc8-a91f-b69a5128f297"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 1, 800, 800])\n"]}]},{"cell_type":"code","source":["# m = nn.Softmax(dim=0)\n","# softmax = m(predDistTransform) # use image\n","softmax = predSeg\n","\n","# print(softmax)"],"metadata":{"id":"BMQ3rsgIoGw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curmask_OrgSize = curMask_orgSize.squeeze().cpu().detach().numpy()\n","curmask_OrgSize_binary = curmask_OrgSize >0\n","plt.imshow(curmask_OrgSize_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"dnDkn4LdoG7y","executionInfo":{"status":"ok","timestamp":1675534607176,"user_tz":360,"elapsed":4,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"1084c4fa-1d09-46ce-cd7e-680259cbb5c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f1d222aa8e0>"]},"metadata":{},"execution_count":98},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[],"metadata":{"id":"PVNLxkA4oHF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zUtAM6v6oHRK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q3cmfvnEtrOv"},"source":["# Create text files with bounding box info for evaluation"]},{"cell_type":"code","source":["model = [t_minus_1_time_step + '_model',time_step + '_model']"],"metadata":{"id":"wfGz2VZs66IG","executionInfo":{"status":"ok","timestamp":1675717291600,"user_tz":360,"elapsed":1100,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"EVZvHMpGt7LH","executionInfo":{"status":"ok","timestamp":1675717291909,"user_tz":360,"elapsed":4,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}}},"outputs":[],"source":["detections_dir = os.path.join(eval_dir, model[1], 'det')\n","if not os.path.exists(detections_dir): \n","    os.makedirs(detections_dir)\n","gt_dir = os.path.join(eval_dir, model[1], 'gt')\n","if not os.path.exists(gt_dir): \n","    os.makedirs(gt_dir)"]},{"cell_type":"code","source":["print(detections_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvyUNmkiJcrc","executionInfo":{"status":"ok","timestamp":1675717291909,"user_tz":360,"elapsed":5,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"53e9caf8-562c-44c8-91b1-a010b17cac38"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/eval/05_Exp3_ContinuousTraining/Trial_04/T1/T1_model/det\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWBfFDtq7i5g","executionInfo":{"status":"ok","timestamp":1675717433579,"user_tz":360,"elapsed":141672,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"114437b3-3477-440a-981e-c4227d20d21f"},"outputs":[{"output_type":"stream","name":"stdout","text":["50/60\n"]}],"source":["iterCount, sampleCount = 0, 0\n","phase = 'test' # 'train'\n","for sample in dataloaders: \n","            \n","    curImg, curLabel, curMask, curMask_orgSize, current_example = sample\n","    \n","    curImg, curLabel, curMask, curMask_orgSize = curImg.to(device), curLabel.to(device), curMask.to(device), curMask_orgSize.to(device)\n","\n","    curImg_squeeze=torch.squeeze(curImg,0)\n","\n","    iterCount += 1\n","    sampleCount += curLabel.size(0)   \n","    \n","    outputs = curmodel(curImg_squeeze)\n","    predSeg = outputs[('segMask', 0)]\n","    predDistTransform = outputs[('output', 0)]\n","\n","    softmax = predSeg\n","    \n","    if iterCount%50==0:\n","        print('{}/{}'.format(iterCount,len(det_datasets)))\n","\n","    #######################################################\n","    ##       ground-truth: labelOrgSize, mask_peaksOrgSize\n","    #######################################################\n","    curmask_OrgSize = curMask_orgSize.squeeze().cpu().detach().numpy()\n","    GTSegMask = curmask_OrgSize >0\n","    GTSegMask = measure.label(GTSegMask, background=0)\n","\n","    props = measure.regionprops(np.squeeze(GTSegMask)) #get the properties of the connected components\n","    bbox = [prop.bbox for prop in props]   #bounding box coordinates for connected components\n","    gt_filename = os.path.join(gt_dir, current_example[0][0] + '_' + current_example[1][0] + '_' + current_example[2][0] + '.txt')\n","    # i=2\n","    gt_info = []\n","    for i in range(len(props)): \n","      class_name=\"finetuned\"   #det\n","      left = bbox[i][1]\n","      top = bbox[i][0]\n","      right = bbox[i][3]\n","      bottom = bbox[i][2]\n","      # predDistTransformCrop = predDistTransform[top:bottom, left:right]\n","      # confidence = np.amax(predDistTransformCrop)\n","      bbox_info = [class_name, str(left), str(top), str(right), str(bottom)]\n","      bbox_info = ' '.join(bbox_info)\n","\n","      gt_info.append(bbox_info)\n","\n","    # fn = open(gt_filename,'w')\n","    fn = open(gt_filename,'a')\n","    for i in gt_info:\n","      fn.write(i + \"\\n\")\n","    fn.close()\n","\n","    ##############################################\n","    ##          prediction: \n","    ##############################################\n","    # create a list of (800x800) prediction distance transforms crops and softmax crops\n","\n","    predDistTransform_crops=[]\n","    softmax_crops = []\n","\n","    for idx in range(0,4):\n","      tmpImg =  predDistTransform[idx,:,:,:].squeeze().cpu().detach().numpy() \n","      predDistTransform_crops.append(tmpImg)\n","\n","    for idx in range(0,4):\n","      tmpImg =  softmax[idx,:,:,:].squeeze().cpu().detach().numpy() \n","      softmax_crops.append(tmpImg)\n","\n","    # create full-sized pred distance transform \n","    mask_OrgSize = curMask_orgSize.squeeze().cpu().detach().numpy()\n","\n","    height,width = mask_OrgSize.shape\n","    predDistTransform=np.zeros_like(mask_OrgSize)  \n","    predDistTransform=predDistTransform.astype(np.float32)\n","\n","    tmp_predDistTransform_1=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_predDistTransform_2=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_predDistTransform_3=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_predDistTransform_4=np.zeros_like(mask_OrgSize).astype(np.float32)\n","\n","\n","    tmp_predDistTransform_1[0:800, 0:800]=predDistTransform_crops[0]\n","    tmp_predDistTransform_2[0:800, width-800:]=predDistTransform_crops[1]\n","    tmp_predDistTransform_3[height-800:, 0:800]=predDistTransform_crops[2]\n","    tmp_predDistTransform_4[height-800:, width-800:]=predDistTransform_crops[3]\n","\n","    predDistTransform = np.maximum.reduce([tmp_predDistTransform_1,tmp_predDistTransform_2,tmp_predDistTransform_3,tmp_predDistTransform_4]) \n","    predDistTransform = gaussian_filter(predDistTransform, sigma=10) # gaussian blur to get rid of shadow\n","    pred_distanceTransform = np.copy(predDistTransform)\n","\n","    # create full-sized softmax\n","    height,width = mask_OrgSize.shape\n","    softmax=np.zeros_like(mask_OrgSize)  \n","    softmax=softmax.astype(np.float32)\n","\n","    tmp_softmax_1=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_softmax_2=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_softmax_3=np.zeros_like(mask_OrgSize).astype(np.float32)\n","    tmp_softmax_4=np.zeros_like(mask_OrgSize).astype(np.float32)\n","\n","    tmp_softmax_1[0:800, 0:800]=softmax_crops[0]\n","    tmp_softmax_2[0:800, width-800:]=softmax_crops[1]\n","    tmp_softmax_3[height-800:, 0:800]=softmax_crops[2]\n","    tmp_softmax_4[height-800:, width-800:]=softmax_crops[3]\n","\n","    tmp_softmax_1[tmp_softmax_1 == 0] = np.nan\n","    tmp_softmax_2[tmp_softmax_2 == 0] = np.nan\n","    tmp_softmax_3[tmp_softmax_3 == 0] = np.nan\n","    tmp_softmax_4[tmp_softmax_4 == 0] = np.nan\n","\n","    # softmax = np.maximum.reduce([tmp_softmax_1,tmp_softmax_2,tmp_softmax_3,tmp_softmax_4]) \n","    softmax =  np.nanmean(np.array([tmp_softmax_1,tmp_softmax_2,tmp_softmax_3,tmp_softmax_4]), axis=0)\n","\n","    # find peaks, zero-out background noise\n","    voting4center = np.copy(pred_distanceTransform)\n","    voting4center[voting4center<0.001] = 0\n","    coord_peaks = feature.peak_local_max(voting4center, min_distance=50, exclude_border=False) #originally min_distance =5, changed to 25\n","\n","    # create detection mask using peaks and predicted radius\n","    detMask = voting4center*0\n","    predRadiusList = []\n","    size = (400,400)\n","    detection_info = []\n","    detection_info2 = []\n","    det_filename = os.path.join(detections_dir, current_example[0][0] + '_' + current_example[1][0] + '_' + current_example[2][0]+ '.txt')\n","\n","\n","    for i in range(coord_peaks.shape[0]):\n","        y, x = coord_peaks[i]\n","        #centerMask[y, x] = 1\n","        # centerMask[y-10:y+10, x-10:x+10] = 1\n","        # predRadiusList += [voting4center[y,x] *100*800/1000 * 800/1000] # /100.0/self.resizeFactor      # why smaller?\n","        # predRadiusList += [voting4center[y,x] *100*1000/1000 * 1000/1000]\n","\n","        left = int(x-(size[0]/2))\n","        left=max(left,0)\n","        top = int(y-(size[0]/2))\n","        top=max(top,0)\n","        right = int(x+(size[0]/2))\n","        right=max(right,0)\n","        bottom = int(y+(size[0]/2))\n","        bottom=max(bottom,0)\n","\n","        tmpCrop = softmax[top:bottom, left:right]\n","        tmpCrop = np.nan_to_num(tmpCrop)\n","        thresh = threshold_otsu(tmpCrop) \n","        tmpCrop = tmpCrop> thresh # binarize\n","        tmpCrop= measure.label(tmpCrop, background=0)\n","        props = measure.regionprops(tmpCrop) #get the properties of the connected components\n","\n","        # diameter = [prop.feret_diameter_max for prop in props]\n","        # diameter = [prop.equivalent_diameter for prop in props]  #diameter for connected components\n","        diameter = [prop.major_axis_length for prop in props]   #diameter for connected components\n","        if len(diameter) !=0 and max(diameter)!=0:\n","          radius = int(max(diameter)/2)\n","          predRadiusList += [radius]\n","          a = len(predRadiusList)-1\n","\n","          tmpMask = voting4center*0\n","          tmpMask = create_circular_mask(tmpMask, [y, x], predRadiusList[a], value=1)\n","\n","          #write bb coords to file\n","          # bbox = [prop.bbox for prop in props]   #bounding box coordinates for connected components\n","\n","          class_name=\"finetuned\"    #det\n","          leftBb = x-radius\n","          leftBb = max(leftBb,0)\n","          topBb = y-radius\n","          topBb= max(topBb,0)\n","          rightBb = x+radius\n","          rightBb = min(rightBb,tmpMask.shape[1] )\n","          bottomBb = y+radius\n","          bottomBb = min(bottomBb,tmpMask.shape[0])\n","\n","          masked_softmax = np.ma.masked_where(tmpMask==0, softmax) \n","          confidence = np.nanmean(masked_softmax)\n","          if confidence > 0.99:\n","            confidence = 0\n","          # bbox_info = [class_name,str(confidence) , str(leftBb), str(topBb), str(rightBb), str(bottomBb)]\n","          bbox_info2 = [class_name, confidence, leftBb, topBb, rightBb, bottomBb]\n","          detection_info2.append(bbox_info2)\n","\n","    # Apply non-max suppression\n","    NMS_bb = nms(detection_info2,conf_threshold=0, iou_threshold=0.3)\n","    NMS_bb = NMS_bb[1]\n","\n","\n","    # fn = open(det_filename,'w')\n","    fn = open(det_filename,'a')\n","    for i in NMS_bb:\n","      fn.write(i + \"\\n\")\n","    fn.close()"]},{"cell_type":"code","source":["print(np.max(tmpCrop))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGZ7jNg1jIIQ","executionInfo":{"status":"ok","timestamp":1675612845987,"user_tz":360,"elapsed":276,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"0c01e82c-302c-4d02-d45c-54ab73903944"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nan\n"]}]},{"cell_type":"code","source":["if math.isnan(np.max(tmpCrop)):\n","  print('null')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rCr8Pcd2j0Zw","executionInfo":{"status":"ok","timestamp":1675612850473,"user_tz":360,"elapsed":270,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"2941c295-4171-455f-b7d2-b75e0c8010e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["null\n"]}]},{"cell_type":"code","source":["plt.imshow(tmpCrop)"],"metadata":{"id":"OYuAygD5lsCB","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1675612972742,"user_tz":360,"elapsed":541,"user":{"displayName":"Jennifer Feng","userId":"02244244752550378593"}},"outputId":"21961275-aad5-45f4-9dc2-2fc76f02edb5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f3cac80a250>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["tmpCrop = np.nan_to_num(tmpCrop)"],"metadata":{"id":"IqMQTDNnTx8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["thresh = threshold_otsu(tmpCrop) \n","tmpCrop = tmpCrop> thresh # binarize"],"metadata":{"id":"GJ0cf97PT_A4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"q0-fi9ShUNmY"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"11kX06MaXNoPtsXtPzqwFKOxKq-QkiU3J","timestamp":1643318796487},{"file_id":"19scDWQ4L79clhNFzHCUF6p4dOSg71kPZ","timestamp":1643243143306},{"file_id":"1LBR2EGgGSmP8F16tB17lU0udI9aGJOVE","timestamp":1642701132152},{"file_id":"1pbz8JGQbXgBsY0i68W2hbMnxv-HZrDzc","timestamp":1641538196383},{"file_id":"1Bf1dJz-tiEa39pj7_5xq6sIqy5sav7tG","timestamp":1641252892862},{"file_id":"1hWiEAazHjKMSjYgci-ZM-4RiRsl-xulx","timestamp":1639780045728},{"file_id":"1dFMFlSD7JumeBNAxDC1GO5I2vY_puom-","timestamp":1639751288360},{"file_id":"1_cGNWaPlb7RGYHbK0p5up6USl8Jqy5l_","timestamp":1638377383878},{"file_id":"1Jovw-ecDYWmrl2byWTMTtfH17w2p_rw1","timestamp":1636216349035},{"file_id":"13s6xpTJ8dA5aUQn1FjgYBwPhfJKO21cM","timestamp":1635990836913},{"file_id":"1wMpFpk61uyI6XoMQjnIvpuaCmVYCRmg6","timestamp":1633643078356}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}